universe = vanilla
executable = /cluster/research-groups/wehrwein/zoo/konnor/colmap/zoo_reconstruction/colmap/manual_registration/pipeline_dense.sh

initialdir = /cluster/research-groups/wehrwein/zoo/konnor/colmap/zoo_reconstruction/colmap/manual_registration

request_cpus   = 16
request_memory = 96GB
request_gpus   = 1
request_disk   = 200GB

should_transfer_files   = YES
when_to_transfer_output = ON_EXIT

# All inputs transferred to execute node SSD — eliminates NFS reads during the job.
# HTCondor places each item at sandbox root using its basename:
#   colmap.sif                   → $SANDBOX/colmap.sif      (no NFS copy in script)
#   sparse/1/cameras.bin         → $SANDBOX/cameras.bin
#   sparse/1/images.bin          → $SANDBOX/images.bin
#   sparse/1/points3D.bin        → $SANDBOX/points3D.bin
#   sparse/1/images/             → $SANDBOX/images/
# Script sets SPARSE_DIR=$SANDBOX so image_undistorter finds everything at sandbox root.
# NFS fallbacks remain in the script in case the cluster .bin-skip quirk still applies.
transfer_input_files = \
    /cluster/research-groups/wehrwein/zoo/containers/colmap.sif, \
    sparse/1/cameras.bin, \
    sparse/1/images.bin, \
    sparse/1/points3D.bin, \
    sparse/1/images

# Transfer back only the final outputs
transfer_output_files = dense/fused.ply, dense/meshed-poisson.ply

output = logs/dense_output.log
error  = logs/dense_error.log
log    = logs/dense_condor.log

getenv = False

queue
